dataset_name: wikitext
dataset_config_name: wikitext-2-raw-v1
config_name: EleutherAI/pythia-410m
tokenizer_name: EleutherAI/pythia-410m
output_dir: ./models/ 
num_train_epochs: 4
model_version: GPTNeoXForCausalLM3
gradient_accumulation_steps: 8 
per_device_train_batch_size: 2
report_to: wandb
with_tracking: true