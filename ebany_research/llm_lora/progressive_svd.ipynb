{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:36<00:00, 18.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7241748480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/user-name-goes-here/.local/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, MistralForCausalLM\n",
    "from ebany_research.llm_lora.changed_mistral import ChangedMistralForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "model_name = \"Open-Orca/Mistral-7B-OpenOrca\"\n",
    "# model_name = \"ebany_research/llm_lora/train_results\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "device = 3\n",
    "model = MistralForCausalLM.from_pretrained(model_name, device_map={\"\": device})\n",
    "model = model.eval()\n",
    "# 29410MiB\n",
    "model = model.half()\n",
    "print(count_parameters(model))\n",
    "# model = MistralForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "# )\n",
    "# model = MistralForCausalLM._from_config(config=config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "dataset = load_dataset(\"openaccess-ai-collective/oo-gpt4-filtered\")\n",
    "dataset = dataset[\"train\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralConfig {\n",
       "  \"_name_or_path\": \"Open-Orca/Mistral-7B-OpenOrca\",\n",
       "  \"architectures\": [\n",
       "    \"MistralForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 32000,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"lora_layers\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4\n",
       "  ],\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"model_type\": \"mistral\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"sliding_window\": 4096,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.37.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32002\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"Open-Orca/Mistral-7B-OpenOrca\")\n",
    "config.lora_layers = [1, 2, 3, 4]\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'system_prompt', 'question', 'response', '__index_level_0__'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 32001,  1587,    13,  1976,   460,   396, 16107, 13892, 28723,\n",
       "           995,   622,   347,  2078,   264,  3638, 28723,   995,  1580,  8270,\n",
       "           264, 10537,   304,  1043,  4372, 28723, 32000, 32001,  2188,    13,\n",
       "            13,    13, 28798,   556,   276,  1987, 11285, 28742, 28713,  3487,\n",
       "         20415,   298,  1912,   706,   684,   272,  6400,   354,   272,  8982,\n",
       "          4150, 28723, 28705, 12628,   272,  2996,   345, 11273,   400,  1987,\n",
       "           767,   863, 14151,   927,   298,   511, 28804,   548,   349,   345,\n",
       "         10847,   264,  4150, 28739,   264,  3716,  4372, 28804,    13,  2820,\n",
       "         16981, 28747, 32000, 32001, 13892,    13,  2501, 28725,   345, 10847,\n",
       "           264,  4150, 28739,   349,   459,   264,  3716,  4372,   298,   272,\n",
       "          2996,   345, 11273,   400,  1987,   767,   863, 14151,   927,   298,\n",
       "           511,  1110, 28723,   415,  2996, 21165,   356,   767, 14151,  3236,\n",
       "           298,   511,  1159,  2492,   272,  4126,  1034,   298, 11285, 28742,\n",
       "         28713,  3487, 20415, 28725,  3210,   821,   272,  4695,  1759,   302,\n",
       "          2170,  3864,   304, 15832,   272,  8982,  4150,  3837, 28723,   330,\n",
       "           680,  7658,  4372,   682, 17516,   272,  9796,   304,  1917,   697,\n",
       "         14151,   553,   298, 16353,   621,  4681,   298,  3754,   288, 11285,\n",
       "         28742, 28713,  3487, 20415,   684,   272,  8982,  4150,  6400, 28723,\n",
       "            13,    13, 11600,  2572,  3716, 11194,   298,   272,  2996,   829,\n",
       "          3024, 28747,    13,    13, 28740, 28723,  9116,   272,  8982,  4150,\n",
       "         28747,  7337,  6852, 11285, 28742, 28713,  3487, 20415, 28725, 14151,\n",
       "           682,   927,   298,   506,   264, 12230,  3028,   302,   767,   272,\n",
       "          8982,  4150,   682,   936,   614, 28723,   851,   829, 17516, 24568,\n",
       "           356,   264,  3608, 28725,   727, 28725,   304,  4723, 28725,   390,\n",
       "          1162,   390, 23689,   272, 11683,  1274, 28723,    13,    13, 28750,\n",
       "         28723, 23184,  4296,   395,  2663, 28747, 14151,  1659,   506,  3236,\n",
       "           298,  7731,   395,  2848,  3282,   304,  2005,  3338,   298,  1316,\n",
       "           395,  4150,  7394, 28725, 20083,   369,   272,  8982,  4150,   682,\n",
       "          8753,   395,  3376, 28742, 28713, 22245,  2464,   304, 22731, 28723,\n",
       "            13,    13, 28770, 28723,  5158, 21824,  4150,  4162, 28747,  7337,\n",
       "          6852, 11285, 28742, 28713,  3487, 20415, 28725, 14151,   682,   927,\n",
       "           298,  1917,  4118, 10936,   302,   272,  4150, 28725,  1259,   390,\n",
       "           272,  7335, 28725,  8059,   697, 28725,  2887,   304, 16195, 28725,\n",
       "          6290,   442, 15175, 28725,   304,   707,  8326, 14841, 28723,    13,\n",
       "            13, 28781, 28723,  8648,   442, 10221,  1304, 25964, 28747,  1791,\n",
       "         25491, 19411, 11285, 28742, 28713,  3487, 20415, 28725, 14151,   993,\n",
       "           506,  3236,   298,  2231,  5277,   442,  7153,  1304, 25964,   369,\n",
       "          4658,   544,  8598,  4162,   684,   272,  8982,  4150, 28723,    13,\n",
       "            13, 28782, 28723,  8702,   653,   264,  2796,  2838, 28747,   560,\n",
       "          1745,   298,  9087,   272,  2442,   302,  8982, 28725, 14151,   682,\n",
       "           927,   298,  1847,   864,   264,  2623,   442,  2796,  2838,   369,\n",
       "           682, 18951, 11285,   298,  8986,   272,  1951,  1671, 24593,   871,\n",
       "          1132,  6032, 28723,    13,    13,  2675,   455, 28725,   272,  2996,\n",
       "         21165,   356,   272,  7892,  5377,  5944,  3030,   354, 14151,   298,\n",
       "         10130,  1034, 11285, 28742, 28713,  3487, 20415,   304,  5227,   706,\n",
       "           684,   272,  8982,  4150,  6400, 28723,  8469, 28725,   345, 10847,\n",
       "           264,  4150, 28739,  1235,   459, 24329,  2962,   272,  6768, 14151,\n",
       "          3236,   298,  1388,  1159,  2492,   272,  4126,  1034, 28723, 32000,\n",
       "         32001, 13892,    13],\n",
       "        [32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000,\n",
       "         32000,     1, 32001,  1587,    13,  1976,   460,   396, 16107, 13892,\n",
       "         28723,  1247,   622,   368,  2111,   368,   264,  3638, 28723,  3604,\n",
       "          5541,   349,   298,  4160,   272,  3638,   390,  7152,  3071,   390,\n",
       "           368,   541, 28723,  4023, 13801,   272,  3638,  1073,  3707, 28733,\n",
       "          1403, 28733,  7691,   304, 16205,   574,  5944, 28723, 32000, 32001,\n",
       "          2188,    13,  5238,   264, 12271,   297, 10177, 28723, 32000, 32001,\n",
       "         13892,    13,  9977, 28705, 28740, 28747, 21815,   264,  3817,   354,\n",
       "           272, 12271, 28723,    13, 28737,   622,  4987,   345,  5773,   660,\n",
       "           311, 28739,   325,  1237,  3914, 28731,   390,   272,  3817, 28723,\n",
       "            13,    13,  9977, 28705, 28750, 28747, 13341,   264, 12143,   304,\n",
       "           264, 28445, 28723,    13, 28737,   622,   938,   272, 12143,   345,\n",
       "          4754, 17749, 28739,   325,   532,  1482, 28731,   297,   272,  2169,\n",
       "         28445, 28723,    13,    13,  9977, 28705, 28770, 28747,  1325, 28768,\n",
       "           786,   380,   272, 12143, 28723,    13, 24091,   345,  5773,   660,\n",
       "           311, 28739,   349,   264, 15816, 28725,  4008, 28733,  9701,  3817,\n",
       "         28725,   315,   622, 11365,   786,   380,   345,  4754, 17749, 28739,\n",
       "           297,   272,  2169, 28445,   390,   345,  4754,   267,   611,    13,\n",
       "            13,  9977, 28705, 28781, 28747,  4849,   272, 12271, 28723,    13,\n",
       "          8479, 28725,   486, 27698,   272,  3817,   304,   272, 11365,   786,\n",
       "           601, 12143, 28725,   272, 12271,   297, 10177,   349, 28747,   345,\n",
       "          5773,   660,   311,  7952,   611,    13,    13, 10202,  2500, 28747,\n",
       "           851, 12271,   349,  3588, 28725,   847,  6461,  6789,  4714, 28725,\n",
       "           304,  6695,  1002,   272,  4979, 11365,   786,   352,   302,   272,\n",
       "         12143,   345,  4754, 17749, 28739,   297,   272,  2169, 28445,   354,\n",
       "           272,  3817,   345,  5773,   660,   311,   611,   661,  7254,  1002,\n",
       "           298,   345,  1014,  3914,  7825, 28739,   297,  4300, 28723, 32000,\n",
       "         32001, 13892,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]]), 'labels': tensor([[    1, 32001,  1587,    13,  1976,   460,   396, 16107, 13892, 28723,\n",
       "           995,   622,   347,  2078,   264,  3638, 28723,   995,  1580,  8270,\n",
       "           264, 10537,   304,  1043,  4372, 28723,  -100, 32001,  2188,    13,\n",
       "            13,    13, 28798,   556,   276,  1987, 11285, 28742, 28713,  3487,\n",
       "         20415,   298,  1912,   706,   684,   272,  6400,   354,   272,  8982,\n",
       "          4150, 28723, 28705, 12628,   272,  2996,   345, 11273,   400,  1987,\n",
       "           767,   863, 14151,   927,   298,   511, 28804,   548,   349,   345,\n",
       "         10847,   264,  4150, 28739,   264,  3716,  4372, 28804,    13,  2820,\n",
       "         16981, 28747,  -100, 32001, 13892,    13,  2501, 28725,   345, 10847,\n",
       "           264,  4150, 28739,   349,   459,   264,  3716,  4372,   298,   272,\n",
       "          2996,   345, 11273,   400,  1987,   767,   863, 14151,   927,   298,\n",
       "           511,  1110, 28723,   415,  2996, 21165,   356,   767, 14151,  3236,\n",
       "           298,   511,  1159,  2492,   272,  4126,  1034,   298, 11285, 28742,\n",
       "         28713,  3487, 20415, 28725,  3210,   821,   272,  4695,  1759,   302,\n",
       "          2170,  3864,   304, 15832,   272,  8982,  4150,  3837, 28723,   330,\n",
       "           680,  7658,  4372,   682, 17516,   272,  9796,   304,  1917,   697,\n",
       "         14151,   553,   298, 16353,   621,  4681,   298,  3754,   288, 11285,\n",
       "         28742, 28713,  3487, 20415,   684,   272,  8982,  4150,  6400, 28723,\n",
       "            13,    13, 11600,  2572,  3716, 11194,   298,   272,  2996,   829,\n",
       "          3024, 28747,    13,    13, 28740, 28723,  9116,   272,  8982,  4150,\n",
       "         28747,  7337,  6852, 11285, 28742, 28713,  3487, 20415, 28725, 14151,\n",
       "           682,   927,   298,   506,   264, 12230,  3028,   302,   767,   272,\n",
       "          8982,  4150,   682,   936,   614, 28723,   851,   829, 17516, 24568,\n",
       "           356,   264,  3608, 28725,   727, 28725,   304,  4723, 28725,   390,\n",
       "          1162,   390, 23689,   272, 11683,  1274, 28723,    13,    13, 28750,\n",
       "         28723, 23184,  4296,   395,  2663, 28747, 14151,  1659,   506,  3236,\n",
       "           298,  7731,   395,  2848,  3282,   304,  2005,  3338,   298,  1316,\n",
       "           395,  4150,  7394, 28725, 20083,   369,   272,  8982,  4150,   682,\n",
       "          8753,   395,  3376, 28742, 28713, 22245,  2464,   304, 22731, 28723,\n",
       "            13,    13, 28770, 28723,  5158, 21824,  4150,  4162, 28747,  7337,\n",
       "          6852, 11285, 28742, 28713,  3487, 20415, 28725, 14151,   682,   927,\n",
       "           298,  1917,  4118, 10936,   302,   272,  4150, 28725,  1259,   390,\n",
       "           272,  7335, 28725,  8059,   697, 28725,  2887,   304, 16195, 28725,\n",
       "          6290,   442, 15175, 28725,   304,   707,  8326, 14841, 28723,    13,\n",
       "            13, 28781, 28723,  8648,   442, 10221,  1304, 25964, 28747,  1791,\n",
       "         25491, 19411, 11285, 28742, 28713,  3487, 20415, 28725, 14151,   993,\n",
       "           506,  3236,   298,  2231,  5277,   442,  7153,  1304, 25964,   369,\n",
       "          4658,   544,  8598,  4162,   684,   272,  8982,  4150, 28723,    13,\n",
       "            13, 28782, 28723,  8702,   653,   264,  2796,  2838, 28747,   560,\n",
       "          1745,   298,  9087,   272,  2442,   302,  8982, 28725, 14151,   682,\n",
       "           927,   298,  1847,   864,   264,  2623,   442,  2796,  2838,   369,\n",
       "           682, 18951, 11285,   298,  8986,   272,  1951,  1671, 24593,   871,\n",
       "          1132,  6032, 28723,    13,    13,  2675,   455, 28725,   272,  2996,\n",
       "         21165,   356,   272,  7892,  5377,  5944,  3030,   354, 14151,   298,\n",
       "         10130,  1034, 11285, 28742, 28713,  3487, 20415,   304,  5227,   706,\n",
       "           684,   272,  8982,  4150,  6400, 28723,  8469, 28725,   345, 10847,\n",
       "           264,  4150, 28739,  1235,   459, 24329,  2962,   272,  6768, 14151,\n",
       "          3236,   298,  1388,  1159,  2492,   272,  4126,  1034, 28723,  -100,\n",
       "         32001, 13892,    13],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,     1, 32001,  1587,    13,  1976,   460,   396, 16107, 13892,\n",
       "         28723,  1247,   622,   368,  2111,   368,   264,  3638, 28723,  3604,\n",
       "          5541,   349,   298,  4160,   272,  3638,   390,  7152,  3071,   390,\n",
       "           368,   541, 28723,  4023, 13801,   272,  3638,  1073,  3707, 28733,\n",
       "          1403, 28733,  7691,   304, 16205,   574,  5944, 28723,  -100, 32001,\n",
       "          2188,    13,  5238,   264, 12271,   297, 10177, 28723,  -100, 32001,\n",
       "         13892,    13,  9977, 28705, 28740, 28747, 21815,   264,  3817,   354,\n",
       "           272, 12271, 28723,    13, 28737,   622,  4987,   345,  5773,   660,\n",
       "           311, 28739,   325,  1237,  3914, 28731,   390,   272,  3817, 28723,\n",
       "            13,    13,  9977, 28705, 28750, 28747, 13341,   264, 12143,   304,\n",
       "           264, 28445, 28723,    13, 28737,   622,   938,   272, 12143,   345,\n",
       "          4754, 17749, 28739,   325,   532,  1482, 28731,   297,   272,  2169,\n",
       "         28445, 28723,    13,    13,  9977, 28705, 28770, 28747,  1325, 28768,\n",
       "           786,   380,   272, 12143, 28723,    13, 24091,   345,  5773,   660,\n",
       "           311, 28739,   349,   264, 15816, 28725,  4008, 28733,  9701,  3817,\n",
       "         28725,   315,   622, 11365,   786,   380,   345,  4754, 17749, 28739,\n",
       "           297,   272,  2169, 28445,   390,   345,  4754,   267,   611,    13,\n",
       "            13,  9977, 28705, 28781, 28747,  4849,   272, 12271, 28723,    13,\n",
       "          8479, 28725,   486, 27698,   272,  3817,   304,   272, 11365,   786,\n",
       "           601, 12143, 28725,   272, 12271,   297, 10177,   349, 28747,   345,\n",
       "          5773,   660,   311,  7952,   611,    13,    13, 10202,  2500, 28747,\n",
       "           851, 12271,   349,  3588, 28725,   847,  6461,  6789,  4714, 28725,\n",
       "           304,  6695,  1002,   272,  4979, 11365,   786,   352,   302,   272,\n",
       "         12143,   345,  4754, 17749, 28739,   297,   272,  2169, 28445,   354,\n",
       "           272,  3817,   345,  5773,   660,   311,   611,   661,  7254,  1002,\n",
       "           298,   345,  1014,  3914,  7825, 28739,   297,  4300, 28723,  -100,\n",
       "         32001, 13892,    13]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "class OpenOrcaDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset=None,\n",
    "        tokenizer=None,\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset_item = self.dataset[idx]\n",
    "        chat = [\n",
    "            {\"role\": \"system\", \"content\": dataset_item[\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": dataset_item[\"question\"]},\n",
    "            {\"role\": \"assistant\", \"content\": dataset_item[\"response\"]},\n",
    "        ]\n",
    "        inputs = self.tokenizer.apply_chat_template(\n",
    "            chat,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "        inputs = self.tokenizer(\n",
    "            inputs,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        for key in inputs.keys():\n",
    "            inputs[key] = inputs[key].squeeze(0)\n",
    "        # print(inputs['input_ids'].shape)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "train_elements = 1000\n",
    "valid_elements = 100\n",
    "\n",
    "train_dataset = OpenOrcaDataset(\n",
    "    dataset=dataset[:train_elements],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "valid_dataset = OpenOrcaDataset(\n",
    "    dataset=dataset[train_elements : train_elements + valid_elements],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "pad_datacollator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    # padding=True,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=pad_datacollator,\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=pad_datacollator,\n",
    ")\n",
    "\n",
    "next(iter(train_dataloader))\n",
    "next(iter(valid_dataloader))\n",
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.94s/it]\n"
     ]
    }
   ],
   "source": [
    "device = 0\n",
    "student_model = MistralForCausalLM.from_pretrained(model_name, device_map={\"\": device})\n",
    "student_model = student_model.eval()\n",
    "student_model = student_model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_layer = 17\n",
    "student_mlp = student_model.model.layers[distill_layer].mlp\n",
    "\n",
    "student_gate_proj = student_mlp.gate_proj.weight.data\n",
    "student_up_proj = student_mlp.up_proj.weight.data\n",
    "student_down_proj = student_mlp.down_proj.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# np.linalg.matrix_rank(student_gate_proj.to(torch.float32).cpu().numpy())\n",
    "# np.linalg.matrix_rank(student_up_proj.to(torch.float32).cpu().numpy())\n",
    "np.linalg.matrix_rank(student_down_proj.to(torch.float32).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64 * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_gate_proj.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "student_gate_proj_num = student_gate_proj.to(torch.float32).cpu().numpy()\n",
    "us, ss, vTs = svds(student_gate_proj_num, k=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14336, 512), (512,), (512, 4096))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us.shape, ss.shape, vTs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "U, S, Vh = torch.linalg.svd(\n",
    "    student_gate_proj.to(torch.float32),\n",
    "    # student_up_proj.to(torch.float32),\n",
    "    # student_down_proj.to(torch.float32),\n",
    "    # student_model.model.embed_tokens.weight.data.to(torch.float32),\n",
    "    full_matrices=False,\n",
    ")\n",
    "\n",
    "\n",
    "area = 4\n",
    "\n",
    "plt.scatter(\n",
    "    torch.arange(0, S.shape[0]).numpy(),\n",
    "    S.cpu().numpy(),\n",
    "    s=area,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "threshold = 128\n",
    "plt.scatter(\n",
    "    torch.arange(0, threshold).numpy(),\n",
    "    S[:threshold].cpu().numpy(),\n",
    "    s=area,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14336, 4096]), torch.Size([4096]), torch.Size([4096, 4096]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, S.shape, Vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAltklEQVR4nO3de3CU9aH/8c+zuSy5bhLIDbJAFEWtAopcor8Dekyl1LFypn84jmfg2ErHnjAj1d85PzlnTu3lj3TGsUfbodLWUabtsfSiwDl4qRwQKBovIKmAmgqmJEASIoFssgm57ff3R9glG5KQze27u3m/ZrY2+zxP8s2jM3nP9/k+zzrGGCMAAABLXLYHAAAAJjdiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYl2h7AcAQCAZ0+fVoZGRlyHMf2cAAAwDAYY9TS0qLp06fL5Rp8/iMmYuT06dPyer22hwEAAEagtrZWRUVFg26PiRjJyMiQ1PvLZGZmWh4NAAAYDp/PJ6/XG/o7PpiYiJHgpZnMzExiBACAGHOlJRYsYAUAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWBUTn00DAADGx/HGVtU2tcmbk6qrc9OtjIEYAQBgkjre2Kpf7vtcZ/2dmpqWrLXLrrISJFymAQBgkqptatNZf6euL8jQWX+nTp5rtzIOYgQAgEnKm5OqqWnJ+qS+RVPTklWUnWJlHFymAQBgkro6N11rl12lk+faVZSdwpoRAAAw8a7OTbcWIUFcpgEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgVUQxUl5erkWLFikjI0N5eXlatWqVqqqqhjxm8+bNchwn7DVlypRRDRoAAMSPiGJk7969Kisr07vvvqudO3eqq6tLd999t/x+/5DHZWZmqq6uLvQ6ceLEqAYNAADiR2IkO7/xxhthX2/evFl5eXk6ePCgli1bNuhxjuOooKBgZCMEAABxbVRrRpqbmyVJOTk5Q+7X2tqqWbNmyev16r777tPRo0eH3L+jo0M+ny/sBQAA4tOIYyQQCGj9+vW6/fbbdeONNw6639y5c/XCCy9o+/bt+s1vfqNAIKDbbrtNJ0+eHPSY8vJyeTye0Mvr9Y50mAAAIMo5xhgzkgO//e1v6/XXX9f+/ftVVFQ07OO6urp0/fXX64EHHtAPf/jDAffp6OhQR0dH6Gufzyev16vm5mZlZmaOZLgAAGCC+Xw+eTyeK/79jmjNSNC6deu0Y8cO7du3L6IQkaSkpCTdfPPNOnbs2KD7uN1uud3ukQwNAADEmIgu0xhjtG7dOm3dulW7d+9WcXFxxD+wp6dHhw8fVmFhYcTHAgCA+BPRzEhZWZleeuklbd++XRkZGaqvr5ckeTwepaSkSJJWr16tGTNmqLy8XJL0gx/8QEuXLtWcOXN0/vx5PfXUUzpx4oQefvjhMf5VAABALIooRp577jlJ0h133BH2/osvvqh/+qd/kiTV1NTI5bo04XLu3DmtXbtW9fX1ys7O1sKFC/XOO+/ohhtuGN3IAQBAXBjxAtaJNNwFMAAAIHoM9+83n00DAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALAqohgpLy/XokWLlJGRoby8PK1atUpVVVVXPO4Pf/iDrrvuOk2ZMkU33XSTXnvttREPGAAAxJeIYmTv3r0qKyvTu+++q507d6qrq0t33323/H7/oMe88847euCBB/TNb35Thw4d0qpVq7Rq1SodOXJk1IMHAACxzzHGmJEe3NjYqLy8PO3du1fLli0bcJ/7779ffr9fO3bsCL23dOlSLViwQJs2bRrWz/H5fPJ4PGpublZmZuZIhwsAACbQcP9+j2rNSHNzsyQpJydn0H0qKipUWloa9t6KFStUUVEx6DEdHR3y+XxhLwAAEJ9GHCOBQEDr16/X7bffrhtvvHHQ/err65Wfnx/2Xn5+vurr6wc9pry8XB6PJ/Tyer0jHSYAAIhyI46RsrIyHTlyRFu2bBnL8UiSNmzYoObm5tCrtrZ2zH8GAACIDokjOWjdunXasWOH9u3bp6KioiH3LSgoUENDQ9h7DQ0NKigoGPQYt9stt9s9kqEBAIAYE9HMiDFG69at09atW7V7924VFxdf8ZiSkhLt2rUr7L2dO3eqpKQkspECAIC4FNHMSFlZmV566SVt375dGRkZoXUfHo9HKSkpkqTVq1drxowZKi8vlyQ9+uijWr58uZ5++mndc8892rJliw4cOKBf/OIXY/yrAACAWBTRzMhzzz2n5uZm3XHHHSosLAy9fve734X2qampUV1dXejr2267TS+99JJ+8YtfaP78+frjH/+obdu2DbnoFQAATB6jes7IROE5IwAAxJ4Jec4IAADAaBEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYRYwAAACriBEAAGAVMQIAAKwiRgAAgFXECAAAsIoYAQAAVhEjAADAKmIEAABYFXGM7Nu3T/fee6+mT58ux3G0bdu2Ifffs2ePHMe57FVfXz/SMQMAgDgScYz4/X7Nnz9fGzdujOi4qqoq1dXVhV55eXmR/mgAABCHEiM9YOXKlVq5cmXEPygvL09ZWVkRHwcAAOLbhK0ZWbBggQoLC/XlL39Zb7/99pD7dnR0yOfzhb0AAEB8GvcYKSws1KZNm/Tyyy/r5Zdfltfr1R133KEPP/xw0GPKy8vl8XhCL6/XO97DBAAAljjGGDPigx1HW7du1apVqyI6bvny5Zo5c6Z+/etfD7i9o6NDHR0doa99Pp+8Xq+am5uVmZk50uECAIAJ5PP55PF4rvj3O+I1I2Nh8eLF2r9//6Db3W633G73BI4IAADYYuU5I5WVlSosLLTxowEAQJSJeGaktbVVx44dC31dXV2tyspK5eTkaObMmdqwYYNOnTqlX/3qV5KkZ555RsXFxfrSl76kCxcu6Pnnn9fu3bv15ptvjt1vAQAAYlbEMXLgwAHdeeedoa8fe+wxSdKaNWu0efNm1dXVqaamJrS9s7NTjz/+uE6dOqXU1FTNmzdP//u//xv2PQAAwOQ1qgWsE2W4C2AAAED0GO7fbz6bBgAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgFTECAACsIkYAAIBVxAgAALCKGAEAAFYRIwAAwCpiBAAAWEWMAAAAq4gRAABgVaLtAQAAADuON7aqtqlN3pxUXZ2bbm0cxAgAAJPQ8cZW/XLf5zrr79TUtGStXXaVtSDhMg0AAJNQbVObzvo7dX1Bhs76O3XyXLu1sRAjAABMQt6cVE1NS9Yn9S2ampasouwUa2PhMg0AAJPQ1bnpWrvsKp08166i7BTWjAAAgIl3dW661QgJ4jINAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWJdoeAAAAmHjHG1tV29Qmb06qrs5NtzoWYgQAgEnmeGOrfrnvc531d2pqWrLWLrvKapBwmQYAgEmmtqlNNU1tSklyqaapTSfPtVsdDzMjAABMQvXNF/RZQ6sypiTKGGN1LMQIAACTUIFnim6akazG1k45jmN1LFymAQBgkvHmpGpmTqraugKamZOqouwUq+NhZgQAgEnm6tx0rV12lU6ea1dRdgp30wAAgIl3dW669QgJivgyzb59+3Tvvfdq+vTpchxH27Ztu+Ixe/bs0S233CK32605c+Zo8+bNIxgqAACIRxHHiN/v1/z587Vx48Zh7V9dXa177rlHd955pyorK7V+/Xo9/PDD+tOf/hTxYAEAQPyJ+DLNypUrtXLlymHvv2nTJhUXF+vpp5+WJF1//fXav3+//vM//1MrVqyI9McDAIA4M+5301RUVKi0tDTsvRUrVqiiomLQYzo6OuTz+cJeAABgbBxvbNWeqjM63thqeyiSJiBG6uvrlZ+fH/Zefn6+fD6f2tsHfuJbeXm5PB5P6OX1esd7mAAATArBR8H/13s1+uW+z6MiSKLyOSMbNmxQc3Nz6FVbW2t7SAAAxIXapjad9Xfq+oIMnfV3Wn8UvDQBt/YWFBSooaEh7L2GhgZlZmYqJWXgh6y43W653e7xHhoAAJOONydVU9OS9Ul9i6amJVt/4Jk0ATFSUlKi1157Ley9nTt3qqSkZLx/NAAA6CfaHngmjeAyTWtrqyorK1VZWSmp99bdyspK1dTUSOq9xLJ69erQ/o888og+//xz/eu//qs+/fRT/exnP9Pvf/97fec73xmb3wAAAAzb8cZW1Ta1RU2ISCOYGTlw4IDuvPPO0NePPfaYJGnNmjXavHmz6urqQmEiScXFxXr11Vf1ne98R88++6yKior0/PPPc1svAAATLLh49ay/U1PTkrV22VVRESSOsf25wcPg8/nk8XjU3NyszMxM28MBACAm7ak6o/96r0bXF2Tok/oW/ePSWVp+be64/bzh/v2OyrtpAADA2IvGxasSH5QHAMCkMt/rkeM4WjQ7Jyou0UjECAAAk0L/9SKLZufYHlIIl2kAAJgE3q9u0l8bWlSQ6Y6ah50FESMAAMS5PVVn9MqHtTp5rl27Pz2jpAQnataLSFymAQAgru2pOqOn36zSqXPtyk5LVnKiS8uuzY2a9SISMyMAAMSt442tevHtap08166AMTrn71Rehjuq1otIxAgAAHHr/eomNbZ0aGpashzH0YzsFD10e3FUzYpIXKYBACAuHW9s1Z//2qjz7V3q7gloTl66yu6cozvm5tke2mWYGQEAIA69X92ket8F3TorWzOyU/X1hUVRGSISMyMAAMSd442tev1InU6c9evUuXYtnJ0ddetE+mJmBACAOPPqR3U6esqnBJej7kBA1xdmRt06kb6IEQAA4sjxxlb9+bMzau3oVltnjxJcLuVmuG0Pa0jECAAAceJ4Y6t+XfE3nfV3KT/DrQTHpVlTU6L6Eo3EmhEAAOLC8cZWPf2nKh040aTWC91KSU7QtQW9d9BE8yUaiRgBACAuvF/dpKqGFiUnJig7zaWUpISovoOmLy7TAAAQ44KfPXOurVNNrR3q7jG6tiAj6i/PBDEzAgBAjDre2KpXPzqtHX+p0xetHcpOS5ZJle64NlcPLp0V9ZdngogRAABi0PHGVn3/f47q0IlzutDVoylJCTrn79RNRZ6YChGJyzQAAMSk96ubdPRUszp7AjJG6gmYqP3smSshRgAAiDHHG1v1fvVZdXQHlOByyXE5KspJ1eN3z42JBav9cZkGAIAYsqfqjDa+9ZmON/rV3RNQUkKCrirI0P+N0RCRiBEAAKJacBaksaVTTf5OvXPsC51ubpckZaYkKXNKkv5x6ayYDRGJGAEAIGr1nQVp6+hWT0CSjJITXOoKGLkTE2LqFt7BECMAAESZ4C27Lx88pYaWCzLGKHAxRBJcjhyXo9nZKbp3wQx99abCmFuw2h8xAgBAFAnOhnxS1yJ/R48cSUZSgktKdLmU5k7QVbm9j3mP5UszfREjAABEgb4PMDvd3K7OnoAcR0pwpOQEl26/ZppuKspSboZbi2bnxPxsSF/ECAAAFgUj5M2PG1Tb1K72zm4luRyZgFGCI6W5kzTP69H/W3l9XAVIX8QIAAAWBCPkf/5yWqfOt6urO6CEBEeJF9eEFGen6fZrcjX34gLVeA0RiRgBAGDCBG/Trapv1YETTfrbF375O3ok6eLaEKN0d6KuyY+vNSFXQowAADCO+gfI6fPt8l/oVsCY3gJR7z9cLqkoO1VfX1gUF3fIRIIYAQBgHPS9DFPXfEEdXQFJRi6XIyPJcaSAkRJd0pSkRM2alhrTT1EdDWIEAIAxMtRlGKk3PHoCRgmOo/QpSSrMStGi2TmTYl3IUIgRAABGqG98nDzXphNn/Trr77zsMkzQlKQEzZqWRoD0Q4wAADBM/T8n5sCJJtU2tamlvVvm4j5JLkdyLr8MU+Bx62tx8sTUsUaMAAAwgP7h0Xfmo+/nxFz6395/dgeMkhK4DBMJYgQAAA0863H6fLtaL3Sp69Kyj94HkkmSjBxHF6Ok94pMUoKj2VNTJ83zQcYKMQIAmFT6RkdQk79Tbx9rVF3zBXV2B2SMFLzzpSfQO+MR/IyY7oBRgktKuPg5MYVZKbo2L0OOpNm5aVyGGQFiBAAQ1wZbZNrW0a3AxesrAWNCMxxS74fSuZzeO18cKfTqO/ORk5Ycl58TYwMxAgCIC8HnelR/0SZPSpJy0pKHXGQattrDXPo+vc8AcZQxJTG05kOSfG1dzHyME2IEABAzBrrEIl26zHLibJu6enrLItElXbq4cvki0wRXb3RIvXe+uCS5ExNU4HHr/7DmY0IRIwCAqNQ/PPqv6+jLmN5LLYGLj/YISOoxUoIz9CLTnLTksO/DZRc7iBEAgBVDzXIMtLaj/7oOl6t3NiP0tdMbIMHFpgkOi0xjBTECABgXkcaGJBlj1HfSI2xtR/91Hbp0mcXlOEpzJygnLVnF09I0Izs1NOvBbEf0I0YAABEbLDSCqr/w68MT59Tc3qkLXT3Diw31PrF0oNtoHccZcF1H38ssREfsIkYAAJcZ6M6UoKHWbkiXgsOoNx4S+lxLGSo2JMmlS+s+BlvbQXTEH2IEACaZvs/daG7vGjQ2+t+ZEgyGK63dCAaHS70LSR0jJbiGHxtN/k5uo51kiBEAiCMD3YHSNzgGe+5G39gY9M6UwZ7JoUvHSr3BYdS7gDRzSpL+fm6uivsEBbGB/ogRAIgBQy0GDcaGpNDnqfR+kFv4+oyhnrsRFhsa+M6UoZ7J0f8W2SZ/pxxJy67N1R1z88boLCBeESMAYEH/D2Ub6HJJ0HAXgyZevFbicjkKBC5fnzHQczeky2NjqDtT+mLtBsYKMQIAY+BKd5cMNoPR/xNh+14ukSJbDBowvduDn6fichQKl6Geu5GZenkEERqYSMQIAPQznEsiI7m7JKjvDEb/T4Ttf7lkOItBdfH4RJej9D6fpxJcI+Jr6woLDkID0YYYARC3Bvuo+MEuiUTyMK6R3F0y2AxGcB6k/+USafiLQYOxQWggFhEjAKLele4Q6Su4TZI+O9MSWswZMEMHRaQP44r07pKhZjAkXTZ70f93YjEo4hkxAmBCjCQohnuHyGBB4XL1/uEPBCRdDILBgmK4D+OSRn53CTMYwMCIEQDDMpJLHmMRFMO6Q2SQoHDU51KI4wwZFJE8jGuwGQwCAxgZYgSIY0M90jtoIi55jCYohnOHyECzFy5HSncnqSjn0mLO4O80WFDwMC7ADmIEiEKRXNIYbPuVHuktRRYUo7nkMdKgiOQOkb7nIrhtbkEGMxVADCBGgDFypVmI4QaFFD4LMdQlDWnwoLjiI701/pc8gttGExSsrwDiHzGCSSeSh1MNNyiuNAsx1AzEQNv7zkIMeReHht4+1CO9paEXZY7VJQ+CAsCVECOIWkNFw0guWwTfj/ThVMMJiivNQkQaFH1nIYa6pCENHhTDfaQ3lzwA2EaMYFTGY5YhuG2waIh0lmE0D6eKJCiGmoUYagai//aBZiGudBfHYNuZjQAQC4iRODSaWzCjYZZBGjoaRnPZItKHUw03KIYzCxFJUDALAWAyIUYm2J6qM9pT1ShJYxYFfbdJo78FMxpmGYaKhkhmGcbi4VTD3cYsBACMzKSOkUg/DGs424faVv2FX29VnZH/Qpd6Agp7uuNoomAsb8GMhlkG6crRMNLLFkGEAwBEj0kbI8cbW/X0n6p04ESTfO1dw/owrCttv9KxPQGjHnNxQaIkjVEUjOUtmNEyyxBENABA/Ju0MVLb1KY63wW5HCd0KUMa2yjof6xz8RW842KsomCsb8Hsj1kGAMB4GlGMbNy4UU899ZTq6+s1f/58/fSnP9XixYsH3Hfz5s166KGHwt5zu926cOHCSH70mPHmpKowc4pOnWu7OFMxtlEw0LEJLkfpSS5lpSbrlplZYR8DLo0uClj8CACIVRHHyO9+9zs99thj2rRpk5YsWaJnnnlGK1asUFVVlfLyBv5o68zMTFVVVYW+7vsH2parc9P1+Iq5+uBvTWps6QjbNlZRwCwCAABXFnGM/PjHP9batWtDsx2bNm3Sq6++qhdeeEFPPPHEgMc4jqOCgoLRjXQcXJ2bThQAAGCZ68q7XNLZ2amDBw+qtLT00jdwuVRaWqqKiopBj2ttbdWsWbPk9Xp133336ejRoyMfMQAAiCsRxcgXX3yhnp4e5efnh72fn5+v+vr6AY+ZO3euXnjhBW3fvl2/+c1vFAgEdNttt+nkyZOD/pyOjg75fL6wFwAAiE8RxchIlJSUaPXq1VqwYIGWL1+uV155Rbm5ufr5z38+6DHl5eXyeDyhl9frHe9hAgAASyKKkWnTpikhIUENDQ1h7zc0NAx7TUhSUpJuvvlmHTt2bNB9NmzYoObm5tCrtrY2kmECAIAYElGMJCcna+HChdq1a1fovUAgoF27dqmkpGRY36Onp0eHDx9WYWHhoPu43W5lZmaGvQAAQHyK+G6axx57TGvWrNGtt96qxYsX65lnnpHf7w/dXbN69WrNmDFD5eXlkqQf/OAHWrp0qebMmaPz58/rqaee0okTJ/Twww+P7W8CAABiUsQxcv/996uxsVHf/e53VV9frwULFuiNN94ILWqtqamRy3VpwuXcuXNau3at6uvrlZ2drYULF+qdd97RDTfcMHa/BQAAiFmOCT4HPYr5fD55PB41NzdzyQYAgBgx3L/f4343DQAAwFCIEQAAYBUxAgAArCJGAACAVRHfTWNDcI0tj4UHACB2BP9uX+lemZiIkZaWFknisfAAAMSglpYWeTyeQbfHxK29gUBAp0+fVkZGhhzHGbPv6/P55PV6VVtbyy3D44RzPL44v+OL8zu+OL/jKxrOrzFGLS0tmj59etgzyPqLiZkRl8uloqKicfv+PHJ+/HGOxxfnd3xxfscX53d82T6/Q82IBLGAFQAAWEWMAAAAqyZ1jLjdbj355JNyu922hxK3OMfji/M7vji/44vzO75i6fzGxAJWAAAQvyb1zAgAALCPGAEAAFYRIwAAwCpiBAAAWDWpY2Tjxo2aPXu2pkyZoiVLluj999+3PaSYsG/fPt17772aPn26HMfRtm3bwrYbY/Td735XhYWFSklJUWlpqT777LOwfZqamvTggw8qMzNTWVlZ+uY3v6nW1tYJ/C2iV3l5uRYtWqSMjAzl5eVp1apVqqqqCtvnwoULKisr09SpU5Wenq6vf/3ramhoCNunpqZG99xzj1JTU5WXl6d/+Zd/UXd390T+KlHpueee07x580IPgiopKdHrr78e2s65HVs/+tGP5DiO1q9fH3qPczxy3/ve9+Q4TtjruuuuC22P2XNrJqktW7aY5ORk88ILL5ijR4+atWvXmqysLNPQ0GB7aFHvtddeM//+7/9uXnnlFSPJbN26NWz7j370I+PxeMy2bdvMX/7yF/O1r33NFBcXm/b29tA+X/nKV8z8+fPNu+++a/785z+bOXPmmAceeGCCf5PotGLFCvPiiy+aI0eOmMrKSvPVr37VzJw507S2tob2eeSRR4zX6zW7du0yBw4cMEuXLjW33XZbaHt3d7e58cYbTWlpqTl06JB57bXXzLRp08yGDRts/EpR5b//+7/Nq6++av7617+aqqoq82//9m8mKSnJHDlyxBjDuR1L77//vpk9e7aZN2+eefTRR0Pvc45H7sknnzRf+tKXTF1dXejV2NgY2h6r53bSxsjixYtNWVlZ6Ouenh4zffp0U15ebnFUsad/jAQCAVNQUGCeeuqp0Hvnz583brfb/Pa3vzXGGPPxxx8bSeaDDz4I7fP6668bx3HMqVOnJmzsseLMmTNGktm7d68xpvd8JiUlmT/84Q+hfT755BMjyVRUVBhjeoPR5XKZ+vr60D7PPfecyczMNB0dHRP7C8SA7Oxs8/zzz3Nux1BLS4u55pprzM6dO83y5ctDMcI5Hp0nn3zSzJ8/f8BtsXxuJ+Vlms7OTh08eFClpaWh91wul0pLS1VRUWFxZLGvurpa9fX1YefW4/FoyZIloXNbUVGhrKws3XrrraF9SktL5XK59N577034mKNdc3OzJCknJ0eSdPDgQXV1dYWd4+uuu04zZ84MO8c33XST8vPzQ/usWLFCPp9PR48encDRR7eenh5t2bJFfr9fJSUlnNsxVFZWpnvuuSfsXEr89zsWPvvsM02fPl1XXXWVHnzwQdXU1EiK7XMbEx+UN9a++OIL9fT0hP3LkKT8/Hx9+umnlkYVH+rr6yVpwHMb3FZfX6+8vLyw7YmJicrJyQntg16BQEDr16/X7bffrhtvvFFS7/lLTk5WVlZW2L79z/FA/w6C2ya7w4cPq6SkRBcuXFB6erq2bt2qG264QZWVlZzbMbBlyxZ9+OGH+uCDDy7bxn+/o7NkyRJt3rxZc+fOVV1dnb7//e/r7/7u73TkyJGYPreTMkaAWFFWVqYjR45o//79tocSV+bOnavKyko1Nzfrj3/8o9asWaO9e/faHlZcqK2t1aOPPqqdO3dqypQptocTd1auXBn6//PmzdOSJUs0a9Ys/f73v1dKSorFkY3OpLxMM23aNCUkJFy2wrihoUEFBQWWRhUfgudvqHNbUFCgM2fOhG3v7u5WU1MT57+PdevWaceOHXrrrbdUVFQUer+goECdnZ06f/582P79z/FA/w6C2ya75ORkzZkzRwsXLlR5ebnmz5+vZ599lnM7Bg4ePKgzZ87olltuUWJiohITE7V371795Cc/UWJiovLz8znHYygrK0vXXnutjh07FtP//U7KGElOTtbChQu1a9eu0HuBQEC7du1SSUmJxZHFvuLiYhUUFISdW5/Pp/feey90bktKSnT+/HkdPHgwtM/u3bsVCAS0ZMmSCR9ztDHGaN26ddq6dat2796t4uLisO0LFy5UUlJS2DmuqqpSTU1N2Dk+fPhwWPTt3LlTmZmZuuGGGybmF4khgUBAHR0dnNsxcNddd+nw4cOqrKwMvW699VY9+OCDof/POR47ra2tOn78uAoLC2P7v19rS2ct27Jli3G73Wbz5s3m448/Nt/61rdMVlZW2ApjDKylpcUcOnTIHDp0yEgyP/7xj82hQ4fMiRMnjDG9t/ZmZWWZ7du3m48++sjcd999A97ae/PNN5v33nvP7N+/31xzzTXc2nvRt7/9bePxeMyePXvCbt9ra2sL7fPII4+YmTNnmt27d5sDBw6YkpISU1JSEtoevH3v7rvvNpWVleaNN94wubm51m/fiwZPPPGE2bt3r6murjYfffSReeKJJ4zjOObNN980xnBux0Pfu2mM4RyPxuOPP2727Nljqqurzdtvv21KS0vNtGnTzJkzZ4wxsXtuJ22MGGPMT3/6UzNz5kyTnJxsFi9ebN59913bQ4oJb731lpF02WvNmjXGmN7be//jP/7D5OfnG7fbbe666y5TVVUV9j3Onj1rHnjgAZOenm4yMzPNQw89ZFpaWiz8NtFnoHMrybz44ouhfdrb280///M/m+zsbJOammr+4R/+wdTV1YV9n7/97W9m5cqVJiUlxUybNs08/vjjpqura4J/m+jzjW98w8yaNcskJyeb3Nxcc9ddd4VCxBjO7XjoHyOc45G7//77TWFhoUlOTjYzZsww999/vzl27Fhoe6yeW8cYY+zMyQAAAEzSNSMAACB6ECMAAMAqYgQAAFhFjAAAAKuIEQAAYBUxAgAArCJGAACAVcQIAACwihgBAABWESMAAMAqYgQAAFhFjAAAAKv+P1v898iNegLuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(\n",
    "    torch.arange(0, ss.shape[0]).numpy(),\n",
    "    ss.T,\n",
    "    s=area,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в целом можно заметить что самые основные значения лежат на первых 8-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32002, 4096])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.model.embed_tokens.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131080192"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32002 * 4096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace to lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14336, 4096])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(U @ torch.diag(S) @ Vh).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 64]) torch.Size([64, 14336])\n"
     ]
    }
   ],
   "source": [
    "# from ebany_research.llm_lora.changed_neox import LinearLora\n",
    "def get_L_R(weights=None, rank=64):\n",
    "    U, S, Vh = torch.linalg.svd(\n",
    "        weights.to(torch.float32),\n",
    "        full_matrices=False,\n",
    "    )\n",
    "\n",
    "    U = U[:, :rank]\n",
    "    S = torch.diag(S[:rank])\n",
    "    Vh = Vh[:rank, :]\n",
    "\n",
    "    L = U @ S\n",
    "    R = Vh\n",
    "    return L, R\n",
    "\n",
    "\n",
    "L, R = get_L_R(student_down_proj)\n",
    "print(L.shape, R.shape)\n",
    "\n",
    "\n",
    "class LinearLora(torch.nn.Module):\n",
    "    def __init__(self, in_dim=768, out_dim=768, r=16, bias=False):\n",
    "        super().__init__()\n",
    "        self.L = torch.nn.Linear(in_dim, r, bias=bias)\n",
    "        self.R = torch.nn.Linear(r, out_dim, bias=bias)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.R(hidden_states)\n",
    "        hidden_states = self.L(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "def assign_new_weights(original_module, original_weights):\n",
    "    L, R = get_L_R(original_weights, rank=16)\n",
    "    original_module.L.weight.data = L\n",
    "    original_module.R.weight.data = R\n",
    "\n",
    "\n",
    "lora_gate_proj = LinearLora(\n",
    "    in_dim=config.hidden_size,\n",
    "    out_dim=config.intermediate_size,\n",
    "    bias=False,\n",
    ")\n",
    "lora_up_proj = LinearLora(\n",
    "    in_dim=config.hidden_size,\n",
    "    out_dim=config.intermediate_size,\n",
    "    bias=False,\n",
    ")\n",
    "lora_down_proj = LinearLora(\n",
    "    in_dim=config.intermediate_size,\n",
    "    out_dim=config.hidden_size,\n",
    "    bias=False,\n",
    ")\n",
    "\n",
    "assign_new_weights(\n",
    "    original_module=lora_gate_proj,\n",
    "    original_weights=student_gate_proj,\n",
    ")\n",
    "assign_new_weights(\n",
    "    original_module=lora_up_proj,\n",
    "    original_weights=student_up_proj,\n",
    ")\n",
    "assign_new_weights(\n",
    "    original_module=lora_down_proj,\n",
    "    original_weights=student_down_proj,\n",
    ")\n",
    "\n",
    "student_mlp.gate_proj = lora_gate_proj\n",
    "student_mlp.up_proj = lora_up_proj\n",
    "student_mlp.down_proj = lora_down_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7241748480\n",
      "7066472448\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(count_parameters(model))\n",
    "print(count_parameters(student_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:09<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3748738026618956\n",
      "tensor(10.7497)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "def eval_model(model):\n",
    "    total_eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            for eval_batch in tqdm.tqdm(valid_dataloader):\n",
    "                # print(eval_batch)\n",
    "\n",
    "                for key in eval_batch.keys():\n",
    "                    eval_batch[key] = eval_batch[key].to(model.device)\n",
    "\n",
    "                loss = model(\n",
    "                    **eval_batch,\n",
    "                )\n",
    "                total_eval_loss += loss.loss.item()\n",
    "    # break\n",
    "    total_eval_loss = total_eval_loss / len(valid_dataloader)\n",
    "    return total_eval_loss\n",
    "\n",
    "\n",
    "teacher_loss = eval_model(model)\n",
    "print(teacher_loss)\n",
    "print(torch.exp(torch.tensor(teacher_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3757719230651855\n",
      "tensor(10.7593)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "student_model = student_model.eval()\n",
    "\n",
    "student_loss = eval_model(student_model)\n",
    "print(student_loss)\n",
    "print(torch.exp(torch.tensor(student_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# model = model.cpu()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### callibrate lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "def train_model(model):\n",
    "    for param in model.named_parameters():\n",
    "        if \"L\" in param[0] or \"R\" in param[0]:\n",
    "            print(param[0])\n",
    "            param[1].requires_grad_(True)\n",
    "        else:\n",
    "            param[1].requires_grad_(False)\n",
    "\n",
    "    total_train_loss = 0\n",
    "    # model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "    accum_iter = 4\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        for batch_id, train_batch in tqdm.tqdm(enumerate(train_dataloader)):\n",
    "            # print(eval_batch)\n",
    "\n",
    "            for key in train_batch.keys():\n",
    "                train_batch[key] = train_batch[key].to(model.device)\n",
    "\n",
    "            loss = model(\n",
    "                **train_batch,\n",
    "            )\n",
    "            loss = loss.loss / accum_iter\n",
    "            # loss = loss.loss\n",
    "\n",
    "            loss.backward()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            if (batch_id + 1) % accum_iter or (batch_id + 1 == len(train_dataloader)):\n",
    "                # print(loss.item())\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                break\n",
    "            # if (batch_id + 1) % accum_iter or (batch_id + 1 == len(train_dataloader)):\n",
    "            # optimizer.step()\n",
    "            # optimizer.zero_grad()\n",
    "        # break\n",
    "    total_train_loss = total_train_loss / len(train_dataloader)\n",
    "    return total_train_loss\n",
    "\n",
    "\n",
    "train_model(model=student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.466512999534607\n",
      "tensor(11.7813)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "student_model = student_model.eval()\n",
    "\n",
    "student_loss = eval_model(student_model)\n",
    "print(student_loss)\n",
    "print(torch.exp(torch.tensor(student_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user-name-goes-here/.local/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"openaccess-ai-collective/oo-gpt4-filtered\")\n",
    "dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=100_000, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'system_prompt', 'question', 'response', '__index_level_0__'],\n",
       "        num_rows: 719045\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'system_prompt', 'question', 'response', '__index_level_0__'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 240/240 [00:11<00:00, 21.81ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 240/240 [00:10<00:00, 22.63ba/s]it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 240/240 [00:10<00:00, 22.58ba/s]it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 3/3 [02:38<00:00, 52.99s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:04<00:00, 22.10ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:22<00:00, 22.06s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub(\"dim/openaccess-ai-collective-oo-gpt4-filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7683)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.exp(torch.tensor(0.57))\n",
    "# 0.54 - ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17_22_45'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"ebany_research/llm_lora/models/openorca_lora_[17][17c_22_45c]\"\n",
    "name = name.split(\"[\")[-1][:-1]\n",
    "name = name.split(\"_\")\n",
    "name = [int(item.replace(\"c\", \"\")) for item in name]\n",
    "name = sorted(name)\n",
    "name = [str(item) for item in name]\n",
    "name = \"_\".join(name)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"model.layers.26.mlp.down_proj.L.weight\".split(\".\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7241748480"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096 * 14336 * 32 * 3 + 1604603904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416543232"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 1024\n",
    "(4096 * r + r * 14336) * 32 * 3 + 1604603904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Kronecker product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.],\n",
       "        [3., 4., 0., 0.],\n",
       "        [0., 0., 1., 2.],\n",
       "        [0., 0., 3., 4.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "mat1 = torch.eye(2)\n",
    "mat2 = torch.ones(2, 2)\n",
    "torch.kron(mat1, mat2)\n",
    "\n",
    "mat1 = torch.eye(2)\n",
    "mat2 = torch.arange(1, 5).reshape(2, 2)\n",
    "torch.kron(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 200]' is invalid for input of size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# B = (U[:, :1] * S[0])\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# B = toeplitz(B.numpy())\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# C = (Vh[:1, :] * S[0])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# A_.shape\u001b[39;00m\n\u001b[1;32m     21\u001b[0m B \u001b[38;5;241m=\u001b[39m (U[:, :\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m S[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqrt())\u001b[38;5;241m.\u001b[39mview(m1, n1)\n\u001b[0;32m---> 22\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mVh\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m A_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mkron(B, C)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mnorm(A\u001b[38;5;241m-\u001b[39mA_,))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 200]' is invalid for input of size 100"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "m, n = 100, 400\n",
    "L = torch.randn(m, n)\n",
    "U, S, Vh = torch.linalg.svd(\n",
    "    L,\n",
    "    full_matrices=False,\n",
    ")\n",
    "m1, m2 = m // 2, 2\n",
    "n1, n2 = 2, n // 2\n",
    "\n",
    "# B = (U[:, :1] * S[0])\n",
    "# B = toeplitz(B.numpy())\n",
    "# C = (Vh[:1, :] * S[0])\n",
    "# C = toeplitz(C.numpy())\n",
    "# B, C  = torch.tensor(B), torch.tensor(C)\n",
    "# A_ = torch.kron(B, C)\n",
    "\n",
    "# A_.shape\n",
    "R = (U[:, :1] * S[0].sqrt()).view(m1, n1)\n",
    "C = (Vh[:, :1] * S[0].sqrt()).view(m2, n2)\n",
    "A_ = torch.kron(R, C)\n",
    "\n",
    "print(\n",
    "    torch.norm(\n",
    "        L - A_,\n",
    "    )\n",
    ")\n",
    "rank = 1\n",
    "print(torch.norm(L - U[:, :rank] @ torch.diag(S[:rank]) @ Vh[:rank, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(U[:, :1] * S[0].sqrt()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(L, A_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(198.7227)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(\n",
    "    L - A_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(196.5673)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 400])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.46382259183655"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(S[0]) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vh[:1, :].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[:, :1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4096]), torch.Size([1024, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vh.shape, U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = U[:, :1]\n",
    "S = torch.diag(S[:1])\n",
    "Vh = Vh[:1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from kronecker_attention_pytorch import KroneckerSelfAttention\n",
    "\n",
    "attn = KroneckerSelfAttention(\n",
    "    dim=32,\n",
    "    heads=16,\n",
    "    dim_heads=64,\n",
    ")\n",
    "\n",
    "x = torch.randn(1, 32, 256, 512)\n",
    "attn(x)  # (1, 32, 256, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 2968.4312\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ebany_research.llm_lora.generalized_kronecker_product_decomposition.gkpd import (\n",
    "    gkpd,\n",
    "    kron,\n",
    ")\n",
    "\n",
    "rank = 256\n",
    "a_shape, b_shape = (rank, 16, 16, 3, 1), (rank, 4, 4, 1, 3)\n",
    "\n",
    "# Full rank\n",
    "a, b = torch.randn(*a_shape), torch.randn(*b_shape)\n",
    "w = kron(a, b)\n",
    "\n",
    "# Approximation\n",
    "a_hat, b_hat = gkpd(w, a_shape[1:], b_shape[1:])\n",
    "w_hat = kron(a_hat, b_hat)\n",
    "\n",
    "# Reconstruction error\n",
    "print(\n",
    "    \"Reconstruction error: {}\".format(\n",
    "        round(\n",
    "            (\n",
    "                torch.linalg.norm((w.reshape(-1) - w_hat.reshape(-1))).detach().numpy()\n",
    "            ).item(),\n",
    "            4,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 16, 16, 3, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = 100, 400\n",
    "m1, m2 = 50, 2\n",
    "n1, n2 = 2, 200\n",
    "a, b = torch.randn((1, m1, n1)), torch.randn((1, m2, n2))\n",
    "w_ = torch.kron(a, b)\n",
    "w = kron(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3303,  0.2095, -0.1851,  ...,  0.3175, -1.5097,  0.5148],\n",
       "        [-0.1194, -0.2758, -0.0448,  ..., -0.1935,  2.1286,  0.0274],\n",
       "        [ 1.2444, -0.7894,  0.6973,  ..., -0.2181,  1.0370, -0.3536],\n",
       "        ...,\n",
       "        [ 0.2061,  0.4758,  0.0773,  ..., -0.2350,  2.5853,  0.0333],\n",
       "        [ 0.2297, -0.1457,  0.1287,  ...,  0.1313, -0.6240,  0.2128],\n",
       "        [ 0.0831,  0.1918,  0.0312,  ..., -0.0800,  0.8799,  0.0113]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3303,  0.2095, -0.1851,  ...,  0.3175, -1.5097,  0.5148],\n",
       "         [-0.1194, -0.2758, -0.0448,  ..., -0.1935,  2.1286,  0.0274],\n",
       "         [ 1.2444, -0.7894,  0.6973,  ..., -0.2181,  1.0370, -0.3536],\n",
       "         ...,\n",
       "         [ 0.2061,  0.4758,  0.0773,  ..., -0.2350,  2.5853,  0.0333],\n",
       "         [ 0.2297, -0.1457,  0.1287,  ...,  0.1313, -0.6240,  0.2128],\n",
       "         [ 0.0831,  0.1918,  0.0312,  ..., -0.0800,  0.8799,  0.0113]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 400])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat, b_hat = gkpd(w, (m1, n1), (m2, n2))\n",
    "w_hat = kron(a_hat, b_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Reconstruction error: {}\".format(\n",
    "        round(\n",
    "            (\n",
    "                torch.linalg.norm((w.reshape(-1) - w_hat.reshape(-1))).detach().numpy()\n",
    "            ).item(),\n",
    "            4,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Mistral weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:38<00:00, 19.06s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, MistralForCausalLM\n",
    "import torch\n",
    "from ebany_research.llm_lora.generalized_kronecker_product_decomposition.gkpd import (\n",
    "    gkpd,\n",
    "    kron,\n",
    ")\n",
    "\n",
    "model_name = \"Open-Orca/Mistral-7B-OpenOrca\"\n",
    "# model_name = \"ebany_research/llm_lora/train_results\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "device = 0\n",
    "model = MistralForCausalLM.from_pretrained(\n",
    "    model_name, device_map={\"\": device}, torch_dtype=torch.bfloat16\n",
    ")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14336, 4096])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_proj = model.model.layers[17].mlp.gate_proj.weight.data.cpu().to(torch.float32)\n",
    "gate_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 18.76\n"
     ]
    }
   ],
   "source": [
    "m1, m2 = 224, 64\n",
    "n1, n2 = 64, 64\n",
    "a_shape = (m1, n1)\n",
    "b_shape = (m2, n2)\n",
    "\n",
    "a_hat, b_hat = gkpd(gate_proj, a_shape, b_shape, max_rank=1024)\n",
    "w_hat = kron(a_hat, b_hat)\n",
    "\n",
    "print(\n",
    "    \"Reconstruction error: {}\".format(\n",
    "        round(\n",
    "            (\n",
    "                torch.linalg.norm((gate_proj.reshape(-1) - w_hat.reshape(-1)))\n",
    "                .detach()\n",
    "                .numpy()\n",
    "            ).item(),\n",
    "            4,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 224, 64]),\n",
       " torch.Size([1024, 64, 64]),\n",
       " torch.Size([14336, 4096]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hat.shape, b_hat.shape, w_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229376"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224 * 64 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 230, 14336])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1024) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m nornmal_mul \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m w_hat\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(nornmal_mul\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 4\u001b[0m kron_mul \u001b[38;5;241m=\u001b[39m \u001b[43mb_hat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m \u001b[38;5;241m@\u001b[39m a_hat\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 230, 4096)\n",
    "nornmal_mul = x @ w_hat.T\n",
    "print(nornmal_mul.shape)\n",
    "kron_mul = b_hat @ x @ a_hat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 64, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14720, 64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2, -1, 64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 17.3346\n"
     ]
    }
   ],
   "source": [
    "rank = 1024\n",
    "U, S, Vh = torch.linalg.svd(\n",
    "    gate_proj.cpu().to(torch.float32),\n",
    "    full_matrices=False,\n",
    ")\n",
    "\n",
    "L = U[:, :rank] @ torch.diag(S[:rank])\n",
    "R = Vh[:rank, :]\n",
    "\n",
    "print(\n",
    "    \"Reconstruction error: {}\".format(\n",
    "        round(\n",
    "            (\n",
    "                torch.linalg.norm(\n",
    "                    (\n",
    "                        gate_proj.cpu().reshape(-1)\n",
    "                        - (U[:, :rank] @ torch.diag(S[:rank]) @ Vh[:rank, :]).reshape(\n",
    "                            -1\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                .detach()\n",
    "                .numpy()\n",
    "            ).item(),\n",
    "            4,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14336, 4096])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14336, 1024]), torch.Size([1024, 4096]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape, R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58720256, 37748736)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14336 * 4096, (14336 * 1024 + 1024 * 4096) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58720256, 56623104, 18874368)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 1024\n",
    "14336 * 4096, (14336 * r + r * 4096) * 3, 14336 * r + r * 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.42437744140625\n",
      "17.4273681640625\n",
      "17.694669723510742\n",
      "17.434450149536133\n",
      "17.55069923400879\n",
      "17.59136390686035\n",
      "17.485074996948242\n",
      "17.43397331237793\n",
      "17.478452682495117\n",
      "17.517587661743164\n",
      "17.489971160888672\n",
      "17.442644119262695\n",
      "17.434368133544922\n",
      "17.459890365600586\n",
      "17.47407341003418\n",
      "17.45974349975586\n",
      "17.438119888305664\n",
      "17.432376861572266\n",
      "17.4425048828125\n",
      "17.450992584228516\n",
      "17.446123123168945\n",
      "17.434650421142578\n",
      "17.429784774780273\n",
      "17.433988571166992\n",
      "17.43879508972168\n",
      "17.437410354614258\n",
      "17.43189239501953\n",
      "17.428497314453125\n",
      "17.429706573486328\n",
      "17.432241439819336\n",
      "17.43203353881836\n",
      "17.429262161254883\n",
      "17.427236557006836\n",
      "17.42763900756836\n",
      "17.428878784179688\n",
      "17.428800582885742\n",
      "17.427410125732422\n",
      "17.42632484436035\n",
      "17.42645263671875\n",
      "17.42702293395996\n",
      "17.426918029785156\n",
      "17.426162719726562\n",
      "17.425640106201172\n",
      "17.425739288330078\n",
      "17.425973892211914\n",
      "17.425827026367188\n",
      "17.425416946411133\n",
      "17.425195693969727\n",
      "17.425270080566406\n",
      "17.425336837768555\n",
      "17.425193786621094\n",
      "17.42498016357422\n",
      "17.424911499023438\n",
      "17.424955368041992\n",
      "17.424943923950195\n",
      "17.424833297729492\n",
      "17.42473793029785\n",
      "17.424728393554688\n",
      "17.424741744995117\n",
      "17.424701690673828\n",
      "17.42463493347168\n",
      "17.424604415893555\n",
      "17.42460823059082\n",
      "17.424596786499023\n",
      "17.424560546875\n",
      "17.424530029296875\n",
      "17.424522399902344\n",
      "17.42452049255371\n",
      "17.424503326416016\n",
      "17.424482345581055\n",
      "17.42447280883789\n",
      "17.424470901489258\n",
      "17.424461364746094\n",
      "17.424448013305664\n",
      "17.424440383911133\n",
      "17.4244384765625\n",
      "17.4244327545166\n",
      "17.42442512512207\n",
      "17.424419403076172\n",
      "17.42441749572754\n",
      "17.424415588378906\n",
      "17.424409866333008\n",
      "17.424406051635742\n",
      "17.42440414428711\n",
      "17.424402236938477\n",
      "17.42439842224121\n",
      "17.424396514892578\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424392700195312\n",
      "17.42439079284668\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424386978149414\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424375534057617\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424379348754883\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424379348754883\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424379348754883\n",
      "17.42437744140625\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.42437744140625\n",
      "17.42437744140625\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424379348754883\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.424381256103516\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.42438316345215\n",
      "17.424381256103516\n",
      "17.424381256103516\n",
      "17.42438316345215\n",
      "17.424381256103516\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.424386978149414\n",
      "17.424386978149414\n",
      "17.424386978149414\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424386978149414\n",
      "17.424386978149414\n",
      "17.424386978149414\n",
      "17.424386978149414\n",
      "17.424386978149414\n",
      "17.424386978149414\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438316345215\n",
      "17.42438316345215\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.42438507080078\n",
      "17.424386978149414\n",
      "17.424386978149414\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424392700195312\n",
      "17.424394607543945\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424386978149414\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.42439079284668\n",
      "17.424388885498047\n",
      "17.424388885498047\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.42439079284668\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424392700195312\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424394607543945\n",
      "17.424396514892578\n",
      "17.424396514892578\n",
      "17.424396514892578\n",
      "17.424396514892578\n",
      "17.42439842224121\n",
      "17.42439842224121\n",
      "17.42439842224121\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424400329589844\n",
      "17.424402236938477\n",
      "17.424402236938477\n",
      "17.424402236938477\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.42440414428711\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.42440414428711\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424406051635742\n",
      "17.424407958984375\n",
      "17.424407958984375\n",
      "17.424407958984375\n",
      "17.424409866333008\n",
      "17.424409866333008\n",
      "17.424409866333008\n",
      "17.42441177368164\n",
      "17.42441177368164\n",
      "17.42441177368164\n",
      "17.42441177368164\n",
      "17.424413681030273\n",
      "17.424413681030273\n",
      "17.424413681030273\n",
      "17.424413681030273\n",
      "17.424413681030273\n",
      "17.424415588378906\n",
      "17.424415588378906\n",
      "17.424415588378906\n",
      "17.424415588378906\n",
      "17.424415588378906\n",
      "17.424415588378906\n",
      "17.424415588378906\n",
      "17.42441749572754\n",
      "17.42441749572754\n",
      "17.424419403076172\n",
      "17.424419403076172\n",
      "17.424421310424805\n",
      "17.424421310424805\n",
      "17.424423217773438\n",
      "17.424423217773438\n",
      "17.424423217773438\n",
      "17.424423217773438\n",
      "17.424423217773438\n",
      "17.424423217773438\n",
      "17.42442512512207\n",
      "17.424423217773438\n",
      "17.424423217773438\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class LinearLora(torch.nn.Module):\n",
    "    def __init__(self, in_dim=768, out_dim=768, r=16, bias=False):\n",
    "        super().__init__()\n",
    "        self.L = torch.nn.Parameter(torch.empty((r, out_dim)))\n",
    "        self.R = torch.nn.Parameter(torch.empty((in_dim, r)))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "    ):\n",
    "        # hidden_states = self.R(hidden_states)\n",
    "        # hidden_states = self.L(hidden_states)\n",
    "        W = torch.fft.ifft2(torch.fft.fft2(self.L)) @ torch.fft.ifft2(\n",
    "            torch.fft.fft2(self.R)\n",
    "        )\n",
    "        # W = torch.fft.fft2(W)\n",
    "        return W\n",
    "\n",
    "\n",
    "\n",
    "net = LinearLora(\n",
    "    in_dim=gate_proj.shape[0],\n",
    "    out_dim=gate_proj.shape[1],\n",
    "    r=1024,\n",
    ")\n",
    "\n",
    "\n",
    "net.L.data = L\n",
    "\n",
    "\n",
    "net.R.data = R\n",
    "\n",
    "\n",
    "\n",
    "gate_proj = gate_proj.to(\"cuda\")\n",
    "\n",
    "\n",
    "net.cuda()\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "epochs = 50000\n",
    "\n",
    "\n",
    "# 17.3346 - svd best\n",
    "\n",
    "\n",
    "# 6.77 - 37748736\n",
    "\n",
    "\n",
    "# 9.52 (64)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    result = net()\n",
    "\n",
    "\n",
    "    loss = torch.linalg.norm((gate_proj.reshape(-1) - result.reshape(-1)))\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.6387e-03,  4.2114e-03,  2.2697e-04,  ...,  2.8992e-03,\n",
       "         -2.7313e-03,  3.7689e-03],\n",
       "        [-1.2436e-03,  2.2125e-04,  7.2479e-04,  ..., -1.1063e-03,\n",
       "         -3.2043e-03,  2.3346e-03],\n",
       "        [-3.1891e-03, -2.5635e-03,  1.5106e-03,  ...,  3.5706e-03,\n",
       "          1.0681e-03, -1.9455e-03],\n",
       "        ...,\n",
       "        [ 3.5667e-04,  5.3406e-04,  2.3460e-04,  ..., -1.2207e-03,\n",
       "          1.1292e-03,  7.6675e-04],\n",
       "        [ 4.6387e-03,  3.7079e-03, -2.4872e-03,  ...,  9.1553e-03,\n",
       "         -4.0894e-03, -3.4332e-03],\n",
       "        [-5.1880e-03,  1.2817e-03,  1.8234e-03,  ..., -3.3875e-03,\n",
       "         -6.9809e-04, -4.9829e-05]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14336, 4096])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_proj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression and the FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "\n",
    "# A = imread(os.path.join(\"..\", \"DATA\", \"dog.jpg\"))\n",
    "# B = np.mean(A, -1)\n",
    "# Convert RGB to grayscale\n",
    "\n",
    "# Bt = np.fft.fft2(B)\n",
    "Bt = np.fft.fft2(gate_proj.numpy())\n",
    "Btsort = np.sort(np.abs(Bt.reshape(-1)))  # sort by magnitude\n",
    "\n",
    "# Zero out all small coefficients and inverse transform\n",
    "for keep in (0.1, 0.05, 0.01, 0.002):\n",
    "    thresh = Btsort[int(np.floor((1 - keep) * len(Btsort)))]\n",
    "    ind = np.abs(Bt) > thresh  # Find small indices\n",
    "    Atlow = Bt * ind  # Threshold small indices\n",
    "    Alow = np.fft.ifft2(Atlow).real  # Compressed image\n",
    "    plt.figure()\n",
    "    plt.imshow(Alow, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Compressed image: keep = \" + str(keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14336, 4096])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bt = np.fft.fft2(gate_proj.numpy())\n",
    "Btsort = np.sort(np.abs(Bt.reshape(-1)))  # sort by magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_proj = gate_proj.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.6387e-03,  4.2114e-03,  2.2697e-04,  ...,  2.8992e-03,\n",
       "         -2.7313e-03,  3.7689e-03],\n",
       "        [-1.2436e-03,  2.2125e-04,  7.2479e-04,  ..., -1.1063e-03,\n",
       "         -3.2043e-03,  2.3346e-03],\n",
       "        [-3.1891e-03, -2.5635e-03,  1.5106e-03,  ...,  3.5706e-03,\n",
       "          1.0681e-03, -1.9455e-03],\n",
       "        ...,\n",
       "        [ 3.5667e-04,  5.3406e-04,  2.3460e-04,  ..., -1.2207e-03,\n",
       "          1.1292e-03,  7.6675e-04],\n",
       "        [ 4.6387e-03,  3.7079e-03, -2.4872e-03,  ...,  9.1553e-03,\n",
       "         -4.0894e-03, -3.4332e-03],\n",
       "        [-5.1880e-03,  1.2817e-03,  1.8234e-03,  ..., -3.3874e-03,\n",
       "         -6.9809e-04, -4.9827e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.fft.ifft2(torch.fft.fft2(gate_proj)).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bt = np.fft.fft2(gate_proj.numpy())  # это веса\n",
    "Btsort = np.sort(np.abs(Bt.reshape(-1)))  # sort by magnitude\n",
    "keep = 0.5\n",
    "thresh = Btsort[int(np.floor((1 - keep) * len(Btsort)))]\n",
    "ind = np.abs(Bt) > thresh  # Find small indices\n",
    "Atlow = Bt * ind  # Threshold small indices <- вот тут много нулей\n",
    "Alow = np.fft.ifft2(Atlow).real  # Compressed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Atlow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAtlow\u001b[49m\u001b[38;5;241m.\u001b[39mreal\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Atlow' is not defined"
     ]
    }
   ],
   "source": [
    "Atlow.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58720256,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Btsort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46976204"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14336, 4096)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14336, 4096)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Atlow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6878, dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm((gate_proj.cpu().reshape(-1) - torch.tensor(Alow).reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117440560\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot access storage of SparseTensorImpl",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(sys\u001b[38;5;241m.\u001b[39mgetsizeof(gate_proj\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat16)\u001b[38;5;241m.\u001b[39mstorage()))\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sys\u001b[38;5;241m.\u001b[39mgetsizeof(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAlow\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:238\u001b[0m, in \u001b[0;36mTensor.storage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39mstorage, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    237\u001b[0m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_warn_typed_storage_removal(stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_typed_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:242\u001b[0m, in \u001b[0;36mTensor._typed_storage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_typed_storage\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 242\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntyped_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m    244\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39muntyped_storage, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot access storage of SparseTensorImpl"
     ]
    }
   ],
   "source": [
    "import torch, sys\n",
    "\n",
    "\n",
    "\n",
    "print(sys.getsizeof(gate_proj.to(torch.float16).storage()))\n",
    "\n",
    "\n",
    "print(sys.getsizeof(torch.tensor(Alow).to_sparse().to(torch.float16).storage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 14335, 14335, 14335],\n",
       "                       [    0,     1,     2,  ...,  4093,  4094,  4095]]),\n",
       "       values=tensor([ 0.0034,  0.0073, -0.0008,  ..., -0.0038,  0.0016,\n",
       "                      -0.0002]),\n",
       "       size=(14336, 4096), nnz=58720256, dtype=torch.float64,\n",
       "       layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(Alow).to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00342234,  0.00729747, -0.00079843, ...,  0.00410324,\n",
       "        -0.00095315,  0.00368936],\n",
       "       [-0.00038301,  0.00045047, -0.00060559, ..., -0.00050858,\n",
       "        -0.00141482,  0.00244444],\n",
       "       [-0.00081623, -0.0026195 ,  0.00104601, ...,  0.00367553,\n",
       "         0.00218834, -0.00219541],\n",
       "       ...,\n",
       "       [-0.00032325,  0.00123588, -0.00047496, ..., -0.00052891,\n",
       "         0.00160069, -0.00171719],\n",
       "       [ 0.00432611,  0.00359148, -0.00118633, ...,  0.00619399,\n",
       "        -0.00471996, -0.0022335 ],\n",
       "       [-0.00406702,  0.00186096,  0.00244315, ..., -0.00376996,\n",
       "         0.00161317, -0.00024044]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 14335, 14335, 14335],\n",
       "                       [    0,     1,     2,  ...,  4093,  4094,  4095]]),\n",
       "       values=tensor([ 0.0034,  0.0073, -0.0008,  ..., -0.0038,  0.0016,\n",
       "                      -0.0002]),\n",
       "       size=(14336, 4096), nnz=58720256, dtype=torch.float16,\n",
       "       layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.6387e-03,  4.2114e-03,  2.2697e-04,  ...,  2.8992e-03,\n",
       "         -2.7313e-03,  3.7689e-03],\n",
       "        [-1.2436e-03,  2.2125e-04,  7.2479e-04,  ..., -1.1063e-03,\n",
       "         -3.2043e-03,  2.3346e-03],\n",
       "        [-3.1891e-03, -2.5635e-03,  1.5106e-03,  ...,  3.5706e-03,\n",
       "          1.0681e-03, -1.9455e-03],\n",
       "        ...,\n",
       "        [ 3.5667e-04,  5.3406e-04,  2.3460e-04,  ..., -1.2207e-03,\n",
       "          1.1292e-03,  7.6675e-04],\n",
       "        [ 4.6387e-03,  3.7079e-03, -2.4872e-03,  ...,  9.1553e-03,\n",
       "         -4.0894e-03, -3.4332e-03],\n",
       "        [-5.1880e-03,  1.2817e-03,  1.8234e-03,  ..., -3.3875e-03,\n",
       "         -6.9809e-04, -4.9829e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alow_torch = torch.tensor(Alow).to(torch.float16).to_sparse()\n",
    "Atlow_torch = torch.tensor(Atlow.real).to(torch.float16).to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528482304"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# before\n",
    "torch._C._cuda_clearCublasWorkspaces()\n",
    "memory_before = torch.cuda.memory_allocated(device)\n",
    "\n",
    "# your tensor or network\n",
    "# gate_proj_copy_1 = gate_proj.to(torch.float16).clone()\n",
    "Atlow_torch_sparse = Atlow_torch.to(device)\n",
    "# after\n",
    "memory_after = torch.cuda.memory_allocated(device)\n",
    "latent_size = memory_after - memory_before\n",
    "\n",
    "latent_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 117440512 - gate_proj.to(torch.float16).clone()\n",
    "# 1056964608\n",
    "# 528482304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 14335, 14335, 14335],\n",
       "                       [    0,     1,     2,  ...,  4092,  4094,  4095]]),\n",
       "       values=tensor([ 46.5000, 101.1250, 336.0000,  ..., -24.1875,\n",
       "                       32.6562,  12.9766]),\n",
       "       device='cuda:0', size=(14336, 4096), nnz=29360127, dtype=torch.float16,\n",
       "       layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Atlow_torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.024398803710938\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "n = 100\n",
    "\n",
    "\n",
    "c = 0.6\n",
    "\n",
    "\n",
    "\n",
    "t1 = torch.randn(100, n, n).to(\"cuda\")\n",
    "\n",
    "\n",
    "t1[torch.rand_like(t1) > c] = 0\n",
    "\n",
    "\n",
    "t2 = t1.to_sparse()\n",
    "\n",
    "\n",
    "\n",
    "print((t2.indices().nelement() * 8 + t2.values().nelement() * 4) / 1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5193e+00,  0.0000e+00,  0.0000e+00,  ..., -2.0527e+00,\n",
       "          -2.6845e-01,  0.0000e+00],\n",
       "         [-7.7700e-01,  1.0802e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 1.2253e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          -1.1418e-01,  4.8530e-01],\n",
       "         ...,\n",
       "         [-2.6703e-01,  0.0000e+00,  0.0000e+00,  ..., -7.9718e-01,\n",
       "          -9.0903e-01,  2.6881e-01],\n",
       "         [ 0.0000e+00, -1.2604e-01, -5.7897e-04,  ..., -5.1620e-02,\n",
       "           0.0000e+00, -1.8099e-01],\n",
       "         [ 2.0012e+00, -5.0144e-01,  3.9186e-01,  ...,  1.5074e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00, -5.4264e-01,  9.0716e-01,  ..., -1.0123e+00,\n",
       "           0.0000e+00, -7.1073e-01],\n",
       "         [ 4.4939e-01, -1.9415e-01,  0.0000e+00,  ...,  1.0840e+00,\n",
       "           0.0000e+00, -1.6075e+00],\n",
       "         [ 1.6987e+00,  0.0000e+00,  0.0000e+00,  ..., -2.5648e-01,\n",
       "           0.0000e+00,  2.3451e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00, -3.3541e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -3.7399e-02,  1.4020e+00,  ...,  0.0000e+00,\n",
       "          -3.3168e-01, -1.3014e+00],\n",
       "         [ 0.0000e+00, -1.3710e-01,  9.1300e-01,  ...,  2.7533e-01,\n",
       "           9.8663e-01, -4.4500e-02]],\n",
       "\n",
       "        [[-5.6347e-01, -1.5533e+00, -1.1093e+00,  ..., -1.4442e+00,\n",
       "           0.0000e+00,  4.8923e-01],\n",
       "         [ 0.0000e+00,  3.7460e-01, -8.2326e-01,  ...,  1.8870e-01,\n",
       "           0.0000e+00, -1.2414e-01],\n",
       "         [-1.2227e+00,  0.0000e+00, -1.7995e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 3.5850e-01, -1.5769e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           1.7785e+00,  0.0000e+00],\n",
       "         [-9.6101e-01,  1.8633e+00, -2.3913e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 4.5698e-01,  1.6946e+00, -7.2262e-01,  ...,  6.1332e-01,\n",
       "          -1.4735e+00,  0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.0269e+00, -1.9034e+00,  0.0000e+00,  ..., -1.3125e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 5.7715e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           6.8831e-01,  5.4015e-01],\n",
       "         [ 5.6197e-01,  7.1095e-01,  2.1833e+00,  ..., -4.3746e-01,\n",
       "           1.5499e+00,  2.0271e+00],\n",
       "         ...,\n",
       "         [-5.2457e-01,  0.0000e+00, -2.2610e-01,  ..., -2.6920e-01,\n",
       "           7.2030e-02,  0.0000e+00],\n",
       "         [-2.8236e-01, -8.6795e-01, -1.2963e+00,  ..., -2.1135e-01,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.2653e-01,  0.0000e+00,  7.1709e-01,  ...,  8.5987e-01,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -1.5670e+00],\n",
       "         [ 0.0000e+00, -1.2543e+00,  0.0000e+00,  ...,  2.1306e-01,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.2936e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -4.3609e-01],\n",
       "         ...,\n",
       "         [ 7.1669e-01, -4.7880e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           1.8727e+00, -1.7434e-01],\n",
       "         [ 7.3796e-03,  3.9465e-01,  6.6363e-01,  ...,  4.8805e-01,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  3.1111e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          -1.4183e+00, -8.1835e-01]],\n",
       "\n",
       "        [[ 6.6923e-01,  1.2285e-01,  5.3571e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.9052e+00,  3.1966e-01, -6.6479e-01,  ..., -1.4349e+00,\n",
       "           1.7118e-01, -1.4049e+00],\n",
       "         [ 0.0000e+00,  3.2412e-01, -4.1430e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [-1.9524e-01, -2.4131e-01,  0.0000e+00,  ..., -2.3070e-01,\n",
       "           2.2533e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  2.3636e+00,  5.0900e-01,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 9.0040e-01,  0.0000e+00,  2.1989e-01,  ...,  0.0000e+00,\n",
       "           9.2969e-01, -1.0726e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "indices expected sparse coordinate tensor layout but got Strided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m((\u001b[43mt1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnelement() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m \u001b[38;5;241m+\u001b[39m t1\u001b[38;5;241m.\u001b[39mvalues()\u001b[38;5;241m.\u001b[39mnelement() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: indices expected sparse coordinate tensor layout but got Strided"
     ]
    }
   ],
   "source": [
    "print((t1.indices().nelement() * 8 + t1.values().nelement() * 4) / 1024**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
