{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading tokenizer_config.json: 100%|██████████| 396/396 [00:00<00:00, 2.71MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 9.73MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 948kB/s]\n",
      "Downloading config.json: 100%|██████████| 567/567 [00:00<00:00, 4.62MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 166M/166M [00:01<00:00, 102MB/s]  \n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "linear = torch.nn.Linear(768, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_weight = linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768, 768]), torch.Size([768]), torch.Size([768, 768]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, v = torch.svd(lin_weight)\n",
    "u.shape, s.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8584e-05, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(lin_weight, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.mT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([768, 6]), torch.Size([6]), torch.Size([768, 6]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, v = torch.svd_lowrank(lin_weight)\n",
    "u.shape, s.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.7942, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(lin_weight, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.mT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393216, 589824)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768 * 256 * 2, 768 * 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32768, 4194304, 3145728)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024 * 8 + 3072 * 8, 1024 * 4096, 1024 * 1024 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1769472, 36864)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768 * 768 * 3, 768 * 8 * 2 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024 * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024 * 8 + 8 * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-777584408"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1_997_624_552 - 2_775_208_960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51511296, 26279936)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50304 * 1024, 50304 * 512 + 512 * 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082981968"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2_775_208_960 - 1_692_226_992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 123]), torch.Size([1, 123]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CustomEmbedding(torch.nn.Embedding):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings: int,\n",
    "        embedding_dim: int,\n",
    "        padding_idx: int | None = None,\n",
    "        max_norm: float | None = None,\n",
    "        norm_type: float = 2,\n",
    "        scale_grad_by_freq: bool = False,\n",
    "        sparse: bool = False,\n",
    "        _weight: Tensor | None = None,\n",
    "        _freeze: bool = False,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            num_embeddings,\n",
    "            embedding_dim,\n",
    "            padding_idx,\n",
    "            max_norm,\n",
    "            norm_type,\n",
    "            scale_grad_by_freq,\n",
    "            sparse,\n",
    "            _weight,\n",
    "            _freeze,\n",
    "            device,\n",
    "            dtype,\n",
    "        )\n",
    "        self.weight = None\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        self.A = Parameter(\n",
    "            torch.empty((num_embeddings, 16), **factory_kwargs),\n",
    "            requires_grad=not _freeze,\n",
    "        )\n",
    "        self.B = Parameter(\n",
    "            torch.empty((16, embedding_dim), **factory_kwargs),\n",
    "            requires_grad=not _freeze,\n",
    "        )\n",
    "        self.B.data.normal_(mean=0.0, std=0.02)\n",
    "        self.A.data.normal_(mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        weight = self.A @ self.B\n",
    "        return F.embedding(\n",
    "            input,\n",
    "            weight,\n",
    "            self.padding_idx,\n",
    "            self.max_norm,\n",
    "            self.norm_type,\n",
    "            self.scale_grad_by_freq,\n",
    "            self.sparse,\n",
    "        )\n",
    "\n",
    "\n",
    "custom_emb = CustomEmbedding(123, 123)\n",
    "default_emb = torch.nn.Embedding(123, 123)\n",
    "custom_emb(torch.tensor([1])).shape, default_emb(torch.tensor([1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.2585e-19, 3.1788e-36, 7.1940e-30,  ..., 7.1955e-30, 0.0000e+00,\n",
       "         7.1944e-30],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Parameter(\n",
    "    torch.empty(\n",
    "        (123, 16),\n",
    "    ),\n",
    "    requires_grad=True,\n",
    ")\n",
    "B = Parameter(\n",
    "    torch.empty(\n",
    "        (16, 123),\n",
    "    ),\n",
    "    requires_grad=True,\n",
    ")\n",
    "\n",
    "(A @ B).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38633472, 26148864)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50304 * 768, 50304 * 256 * 2 + 2 * 256 * 768"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
